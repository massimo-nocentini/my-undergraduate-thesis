\chapter{Algoritmi}
\label{chapter:theoretical-background}
In questo capitolo affronteremo gli algoritmi alla base delle
implementazioni da un punto di vista teorico. Vedremo la tecnica di
visita del grafo che abbiamo adottato e diverse soluzioni per il
calcolo delle componenti fortemente connesse.

\section{Alcune definizioni}
\label{subsection:some-definitions}
Un grafo $G$ \`e una coppia $(V, E)$ dove $V$ \`e un insieme di
vertici ed $E$ \`e un insieme di archi. Pi\`u precisamente $E$ \`e una
relazione binaria tale che $E \subseteq V \times V$.

Un grafo $G$ si dice \emph{non orientato} se $E$ \`e una relazione
simmetrica, altrimenti si dice \emph{orientato}. Sia $G$ un grafo
orientato, un cammino da un vertice $v_{i}$ ad un vertice $v_{j}$ \`e
una sequenza di vertici $(v_{i}, v_{i+1}, \cdots, v_{j-1}, v_{j})$
tale che $\forall k \in [i, j-1]$ si ha $(v_{k},v_{k+1}) \in E$. Tale
cammino lo indicheremo con la scrittura $v_{i} \rightarrow^{*}
v_{j}$. Nel caso di un grafo non orientato indichiamo un cammino con
la scrittura $v_{i} -^{*} v_{j}$.

Un cammino $\pi = v_{i} \rightarrow^{*} v_{i}$ \`e chiamato un cammino
\emph{chiuso}. In particolare, un cammino chiuso \`e un \emph{ciclo}
quando tutti gli archi che lo compongono sono distinti e $v_{i}$ \`e
l'unico vertice che appare esattamente due volte in $\pi$. Due cicli
che sono permutazioni l'uno dell'altro sono indistinguibili e,
pertanto, si considerano essere lo stesso ciclo.

Un grafo non orientato \`e \emph{connesso} se $\forall v, w \in V$
esiste un cammino $\pi$ tale che $\pi = v -^{*} w$. Un grafo orientato
\`e \emph{fortemente connesso} se $\forall v, w \in V$ esistono due
cammini $\pi_{1}, \pi_{2}$ tali che $\pi_{1} = v \rightarrow^{*} w
\wedge \pi_{2} = w \rightarrow^{*} v$.

Un grafo orientato $T$ \`e un \emph{albero} se valgono le seguenti
propriet\`a:
\begin{itemize}
\item la versione non orientata di $T$ \`e connessa;
\item esiste esattamente un vertice $v$ tale che $\forall w \in V: (w,
  v) \not \in E$. Il vertice $v$ viene chiamato \emph{radice} di $T$;
\item tutti i vertici distinti dal vertice \emph{radice} hanno
  esattamente un arco entrante, ovvero $\forall w \not = radice(T),
  \exists!r: (r, w) \in E$.
\end{itemize}
Un insieme di alberi viene definito \emph{foresta}.  

Sia $G$ un grafo orientato. Possiamo definire una relazione
d'equivalenza sull'insieme di vertici come segue: due vertici $v$ e
$w$ sono equivalenti se esiste un cammino chiuso $\pi = v
\rightarrow^{*} v$ che contiene $w$. Chiamiamo $V_{i}$ le classi
d'equivalenza di questa relazione e sia $G_{i}$ un sotto grafo di $G$
tale che $G_{i} = (V_{i}, E_{i})$, con $E_{i} = \{(r,s) \in E: r,s \in
V_{i} \}$. Allora:
\begin{itemize}
\item ogni $G_{i}$ \`e fortemente connesso;
\item nessun $G_{i}$ \`e un sotto grafo proprio di un sotto grafo
  connesso di $G$.
\end{itemize}
I sotto grafi $G_{i}$ sono chiamati \emph{componenti fortemente
  connesse} di $G$.


\section{Visitare un grafo}

La visita di un grafo $G$ \`e una procedura fondamentale che permette
di estrarre informazioni sulla struttura di $G$. Per questo motivo \`e
importante avere implementazioni che richiedono tempo polinomiale per
terminare la computazione.

\subsection{Il concetto di visita}
Supponiamo che siano dati un grafo $G = (V, E)$ e due vertici $v,w \in
V$. Per capire il concetto di visita poniamoci la seguente domanda:
come possiamo determinare se esiste un cammino $v \rightarrow^{*} w$?

Una risposta \`e quella di costruire un insieme $W$ di vertici
raggiungibili da $v$ utilizzando una sequenza di archi in $E$, e
rispondere si se e solo se $w \in W$.  Il processo di costruzione
dell'insieme $W$ viene definito \emph{visita} del grafo a partire dal
vertice $v$ e diremo \emph{visitato} ogni vertice $s \in W$.

Osserviamo che la visita di un grafo \`e un'operazione ben diversa
dall'iterare sui suoi vertici, in quanto:
\begin{itemize}
\item iterando sull'insieme $V$ si raggiunge esattamente ogni vertice
  per definizione, mentre visitando il grafo si raggiunge un sotto
  insieme $V' \subseteq V$;
\item l'ordine seguito iterando sull'insieme $V$ non \`e dipendente
  dalla relazione $E$ del grafo, bens\`i pu\`o essere stabilito a
  priori. Invece l'ordine con cui vengono raggiunti i vertici in una
  visita \`e un fattore che caratterizza una visita da un'altra.
\end{itemize}

Riassumendo quanto detto in sopra, la visita di un grafo $G$ a partire
da un vertice $v$ produce una permutazione $\pi$ di vertici
$(v_{\pi_{1}}, \ldots, v_{\pi_{s}})$, ognuno di essi raggiungibile da
$v$, di cui \`e interessante l'ordine codificato nella permutazione,
ovvero l'ordine in cui i vertici vengono visitati.

\subsection{Visita in profondit\`a}
Nella precedente sezione abbiamo dato l'idea fondamentale di cosa
significa visitare un grafo. Vi sono molte strategie che differenziano
due visite, caratterizzate dalla modalit\`a con cui si sceglie il
prossimo arco da percorrere.

Quella che differenzia la \emph{visita in profondit\`a}, o
\emph{Depth-First Search}, \`e la seguente:
\begin{quotation}
  Nella selezione del prossimo arco da percorrere, si sceglie un arco
  non ancora percorso uscente dal vertice pi\`u recentemente
  raggiunto.
\end{quotation}
Possiamo mantenere l'insieme dei vertici \emph{pi\`u recentemente
  raggiunti} in una \emph{pila}.

Per capire meglio il pattern di questa tecnica supponiamo di iniziare
la visita dal vertice $v$. Prima $v$ viene visitato, poi si sceglie un
arco non ancora percorso $(v, v_{1}) \in E$, raggiungendo il vertice
$v_{1}$. Adesso $v_{1}$ viene visitato e si applica al vicinato di
$v_{1}$ quanto fatto al vicinato di $v$. Solo quando tutti i vertici
nel vicinato di $v_{1}$ vengono visitati \`e possibile visitare il
secondo vicino $v_{2}$ di $v$ (\`e possibile che $v_{2}$ venga
visitato durante la visita di $v_{1}$, in questo caso non \`e
necessaria nessuna operazione su $v_{2}$).

Il complemento ``in profondit\`a'' cattura l'idea che la visita
procede allontanandosi sempre pi\`u dal punto di partenza, spostandosi
da un vertice ad un vicino di tale vertice, ad un vicino del vicino di
tale vertice e cos\`i via, tornando indietro solo quando si raggiunge
un vertice il cui vicinato \`e completamente visitato oppure vuoto.
\\\\
Papadimitriou, in \cite{Algorithms} pagina 83, vede questa visita come
un algoritmo per risolvere un labirinto, identificandone le idee
principali in forma diversa rispetto a come le abbiamo esposte sopra:

\begin{quotation}
  [...] the reachability problem is rather like exploring a
  labyrinth[...], a careless choice of passage might lead you around
  in circles or might cause you to return to passages that you
  previously saw but did not investigate.[...] Everybody knows that
  all you need to explore a labyrinth is a ball of string and a piece
  of chalk. The chalk prevents looping, the string always takes you
  back...
\end{quotation}
Riportando questa citazione su quanto detto sopra, il concetto di
vertice visitato corrisponde al \emph{chalk}, mentre la pila
contenente i vertici pi\`u recentemente raggiunti corrisponde alla
\emph{ball of string}.

\subsection{Pseudo codice e complessit\`a}
Formalizziamo la visita in profondit\`a col seguente pseudo codice:
\begin{lstlisting}
    procedura DFS(G = (V, E))
      per ogni v in V:
        visitato[v] = falso

      per ogni v in V:
        se non visitato[v]:
          visita(v, E)

    procedura visita(v, E):
      visitato[v] = vero
      previsita(v)
      per ogni arco (v, u) in E:
        se non visitato[u]: visita(u, E)
      postvisita(v)
\end{lstlisting}
Facciamo una breve analisi della complessit\`a. La prima osservazione
da fare \`e che ogni vertice viene esaminato una e una sola volta
grazie al vettore \emph{visitato}. Durante l'esplorazione di un
vertice si spende una quantit\`a costante di tempo sia per aggiornare
il vettore \emph{visitato}, sia per le invocazioni delle funzioni
$previsita$ e $postvisita$.

Per quanto riguarda la scansione del vicinato, abbiamo per ogni
vertice un impiego di tempo diverso: per questo motivo ci conviene
considerare gli archi in modo dipendente da come la relazione $E$
viene rappresentata in macchina. Supponendo di codificarla con
\emph{liste di adiacenza}, ogni arco verr\`a visitato una e una sola
volta in caso di grafo orientato, altrimenti esattamente due volte in
caso di grafo non orientato. Segue che il tempo impiegato dalla visita
\`e $O(|V| + |E|)$, lineare nella lunghezza dell'input e quindi
polinomiale come avevamo richiesto ad inizio capitolo.

\subsection{Punti di estensione}
\label{subsection:dfs-extension-point}
\`E possibile ``personalizzare'' lo schema classico della visita in
profondit\`a in modo da inserire dei ``punti di estensione'' che
permettano di eseguire del comportamento dedicato all'avvenire di
eventi salienti durante l'esecuzione della visita. Nello pseudo codice
che abbiamo riportato ne abbiamo inseriti due, rappresentati dalle
funzioni $previsita$ e $postvisita$.

Facciamo un'osservazione sul loro utilizzo e supponiamo che $G$ sia un
albero. Se implementiamo la visita usando solo la funzione $previsita$
allora il risultato \`e equivalente ad una visita \emph{prefissa}
dell'albero, mentre usando solo la funzione $postvisita$ allora
il risultato \`e equivalente ad una visita \emph{postfissa}.

Come vedremo nella Sezione \ref{subsection:kosaraju-algorithm}, un
altro utilizzo \`e quello di associare ad ogni vertice $v$ una coppia
di interi che indicano l'intervallo di tempo durante il quale $v$
rimane nella pila dei vertici raggiunti.

\subsection{Costruzione dell'albero DFS}
Un risultato della visita in profondit\`a di un grafo non orientato $G
= (V, E)$, parallelo alla verifica dell'esistenza di un cammino tra
due vertici, \`e la costruzione di un albero ricoprente di $G$. Per
\emph{albero ricoprente} si intende un sotto grafo $T$ di $G$ tale che
$T = (V, E')$, con $E' \subseteq E$, e che $T$ sia un albero.

\`E possibile costruire l'insieme $E'$ aggiungendo gli archi $(v, u)
\in E$ tali che $visitato[u] = falso$ quando l'arco viene analizzato
nella procedura di visita.

Vedremo nel Capitolo \ref{chapter:study} come la costruzione di tali
alberi verr\`a raggiunta da una specifica funzionalit\`a del nostro
progetto.

\section{Ricerca delle componenti fortemente connesse}

In questa sezione faremo una panoramica degli algoritmi pi\`u
conosciuti in letteratura per la ricerca di componenti fortemente
connesse di un grafo orientato. Ognuno dei seguenti algoritmi \`e in
realt\`a una variante della visita in profondit\`a: attraverso piccole
modifiche e l'utilizzo dei punti di estensione cattura una idea che lo
caratterizza.

\subsection{Kosaraju: componenti pozzo e inversione del grafo}
\label{subsection:kosaraju-algorithm}
Quest'idea non introduce nessuna modifica allo schema che abbiamo
visto, bens\`i utilizza la procedura \emph{DFS} due volte su grafi in
input differenti.

Un'osservazione che possiamo fare sulla procedura $visita$,
invocata sul vertice $u$, \`e che questa termina quando tutti i
vertici raggiungibili da $u$ sono stati esplorati. Questo ci permette
di ragionare come segue:
\begin{quotation}
  Supponiamo di conoscere la decomposizione in componenti fortemente
  connesse di un grafo. Sia $C_{i}$ una di queste, tale che sia un
  pozzo (ovvero che non abbia archi uscenti nel \emph{meta grafo} che
  ha come vertici le componenti fortemente connesse di cui stiamo
  ipotizzando l'esistenza). Se $v \in C_{i}$ allora $C_{i} =
  visita(v)$ (per comodit\`a supponiamo che $visita$ ritorni
  l'insieme di vertici raggiungibili da $v$).
\end{quotation}

Con la precedente osservazione abbiamo un metodo per trovare una
componente fortemente connessa, non sappiamo per\`o come trovare n\'e il
vertice $v$ n\'e le altre componenti.

Prima di continuare implementiamo le due funzioni $previsita$ e
$postvisita$ in modo da associare ad ogni vertice, rispettivamente il
momento in cui viene raggiunto e il momento in cui il suo vicinato
viene completamente visitato. Di questi due momenti siamo interessati
al secondo che chiamiamo \emph{post}.

Adesso che abbiamo definito la coppia di momenti possiamo osservare
che:
\begin{quotation}
  il vertice con associato il pi\`u grande valore \emph{post}
  % calcolato dall'invocazione di un \emph{visita in profondit\`a},
  appartiene ad una componente fortemente connessa sorgente.
\end{quotation}

\`E facile individuare tali vertici, in quanto sono i vertici per i
quali la procedura \emph{DFS} invoca la procedura
$visita$. Per\`o questo non \`e sufficiente per usare la
precedente osservazione, in quanto quello che si richiede \`e un
vertice che appartenga ad una componente fortemente connessa pozzo.

Per risolvere questo problema possiamo invertire il grafo in input
calcolando $G^{R} = (V, E^{-1})$, con $E^{-1} = \{(w, v): (v, w) \in
E\}$.

Notiamo che le componenti fortemente connesse non cambiano la loro
composizione in $G^{R}$. Sia $C_{i}$ una di queste: per definizione di
componente fortemente connessa, per ogni coppia di vertici $v_{1},
v_{2}$ esiste un cammino $c_{1} = v_{1}\rightarrow^{*} v_{2}$ ed un
cammino $c_{2} = v_{2}\rightarrow^{*} v_{1}$. Invertendo la direzione
degli archi, i due cammini continuano ad esistere ($c_{1}$ gioca il
ruolo di $c_{2}$ e viceversa) e quindi la relazione di connessione
forte \`e chiusa rispetto alla operazione $\cdot ^{R}$. Il vantaggio
di passare a $G^{R}$ \`e che le componenti sorgenti di $G$ diventano
componenti pozzi di $G^{R}$.

Adesso possiamo eseguire una visita in profondit\`a su $G^{R}$
e, per la seconda osservazione in quota, il vertice con associato il
massimo \emph{post} appartiene ad una componente fortemente connessa
sorgente in $G^{R}$ e, di conseguenza, ad una componente fortemente
connessa pozzo in $G$, che \`e quello che volevamo.

Possiamo quindi invocare una visita in profondit\`a sul grafo di input
$G$, scansionando i vertici in ordine decrescente di
\emph{post}. Cos\`i facendo, per la prima osservazione in quota,
identificheremo le componenti fortemente connesse.
%  I vertici visitati durante ogni invocazione della
% procedura $visita$ eseguita dalla procedura \emph{DFS} \`e una
% componente fortemente connessa del grafo $G$.

Questo algoritmo lavora in tempo lineare, richiedendo circa il doppio
del tempo richiesto dalla visita in profondit\`a.

\subsection{Tarjan: una pila e la funzione $lowlink$}
\label{subsection:tarjan-algorithm}
La caratteristica di questo algoritmo \`e quella di modificare lo
schema di una visita in profondit\`a, implementando i due punti di
estensione ed aggiungendo della logica sia dopo aver terminato
l'invocazione ricorsiva su ogni vertice non ancora raggiunto del
vicinato, sia nel caso si incontrino vertici gi\`a visitati.

Gli strumenti utilizzati da questa variante sono:
\begin{description}
\item[funzione $numero$] ad ogni vertice $v$ associa un intero che
  rappresenta il momento in cui $v$ viene visitato oppure, da un altro
  punto di vista, quanti vertici sono gi\`a stati visitati prima di
  $v$;
\item[funzione $lowlink$] ad ogni vertice $w$ associa un vertice $v$
  antenato di $w$, tale che:
  \begin{displaymath}
    numero(v) = \min_{a \in antenati(w)}\{numero(a)\}
\end{displaymath}
\item[una pila] che contiene tutti i vertici che sono stati visitati
  durante l'algoritmo ma che ancora non sono stati associati ad una
  componente fortemente connessa.
\end{description}

Inoltre Tarjan classifica gli archi dopo aver applicato una visita in
profondit\`a in questo modo:
\begin{description}
\item[archi dell'albero DFS] sono tutti gli archi che hanno permesso
  di raggiungere un vertice non ancora visitato e vengono indicati con
  $\rightarrow$;
\item[archi in avanti] questi archi non appartengono a nessun albero
  \emph{DFS} e collegano un antenato ad un suo discendente;
\item[archi all'indietro] questi archi non appartengono a nessun
  albero \emph{DFS} e collegano un discendente ad un suo antenato.
  Vengono indicati con $\cdot\rightarrow$;
\item[archi trasversali] questi archi non appartengono a nessun albero
  \emph{DFS} e collegano due vertici appartenenti a sotto alberi
  differenti (questi sotto alberi posso appartenere sia allo stesso
  albero \emph{DFS}, sia a due alberi \emph{DFS} disgiunti). Questi
  archi sono indicati con $\cdot\rightarrow$.
\end{description}
Un'osservazione da fare riguardo agli archi trasversali \`e la
seguente: se $e = (v, w) \in E$ \`e un arco trasversale allora
$numero(w) < numero(v)$ ovvero, graficamente parlando, $e$ \`e
orientato da destra verso sinistra. Motivare questo non \`e difficile:
supponiamo per assurdo che $e$ non abbia questa direzione, allora
durante una visita, o verrebbe inserito in un albero \emph{DFS} (e
quindi sarebbe un arco del primo tipo, una contraddizione) oppure
raggiungerebbe un vertice gi\`a visitato (e quindi sarebbe un arco in
avanti o all'indietro, un'altra contraddizione).

Vediamo adesso le idee principali alla base dell'algoritmo. La prima
di queste \`e la seguente:
\begin{quotation}
  Sia $C$ una componente fortemente connessa e siano $v, w$ due
  vertici tali che $v, w \in C$. Sia $F$ la foresta di alberi
  \emph{DFS} generati dall'esecuzione di una visita in
  profondit\`a. Allora $v, w$ hanno un antenato comune nella foresta
  $F$. Inoltre, sia $u$ un antenato comune di $v, w$ tale che:
  \begin{displaymath}
    numero(u) = \min_{a \in (antenati(v)\cap antenati(w))}\lbrace numero(a)\rbrace
  \end{displaymath}
  allora $u \in C$.
\end{quotation}
Per far vedere la precedente osservazione supponiamo che durante una
visita in profondit\`a il vertice $v$ sia visitato prima di $w$
($numero(v) < numero(w)$) e, dato che $v,w$ appartengono alla stessa
componente fortemente connessa, esista un cammino chiuso $\pi = v
\rightarrow^{*} v$ che contiene $w$.

Chiamiamo $T_{u}$ il pi\`u piccolo albero che ha come radice $u$ e che
contiene tutti i vertici attraversati dal cammino $\pi$. Il sotto
albero $T_{u}$ esiste in quanto il cammino $\pi$ pu\`o passare da un
albero $T_{M}$ ad un albero $T_{m}$ della foresta $F$ se:
\begin{displaymath}
  \max_{r \in T_{m}}\{numero(r)\} < \min_{s \in T_{M}}\{numero(s)\}
\end{displaymath}
percorrendo \emph{archi trasversali}, mentre non arriver\`a in alberi
con numerazioni maggiori rispetto all'albero di provenienza.

Osserviamo per\`o che se il cammino $\pi$, partendo da $v$,
attraversasse pi\`u di un albero, non sarebbe in grado di tornare
nella componente connessa che contiene $w$ perch\`e gli archi
trasversali non possono orientarsi a destra. Questo prova l'esistenza
di $T_{u}$ e $v,w$ hanno un comune antenato, ma dato che $T_{u}$
contiene tutti i vertici attraversati da $\pi$, $u$ essendo in $T_{u}$
(\`e la sua radice) viene attraversato a sua volta da $\pi$ e, di
conseguenza, appartiene alla stessa componente fortemente connessa che
contiene $v, w$.
\\\\
Adesso possiamo affrontare la seconda idea che ci dar\`a un metodo per
identificare le componenti fortemente connesse:
\begin{quotation}
  Sia $C$ una componente fortemente connessa. Allora i vertici $v_{i}
  \in C$ appartengono ad uno stesso sotto albero nella foresta
  \emph{DFS}. Inoltre la radice del sotto albero viene chiamata
  \emph{testa} della componente fortemente connessa $C$.
\end{quotation}
La precedente idea riduce il problema di individuare le componenti
fortemente connesse al problema di identificare i vertici
\emph{radice} di sotto alberi della foresta. Tarjan propone il
seguente criterio per individuare i vertici radice:
\begin{quotation}
  Un vertice $v$ \`e \emph{testa} di una componente fortemente
  connessa se e solo se $numero(v) = lowlink(v)$.
\end{quotation}
Quanto detto in quota ha bisogno di alcune spiegazioni. La prima cosa
che dobbiamo definire \`e come calcolare $lowlink(v)$:
\begin{displaymath}
  \begin{split}
    lowlink(v) &= \min \{ \{numero(v)\} \cup \\
      & \{numero(w): (\exists r \in V: v \rightarrow^{*} r
      \cdot\rightarrow w) \\
      & \wedge (\exists u \in V: u \rightarrow^{*} v \wedge u
      \rightarrow^{*} w \wedge \\
      & u,w \in C, \text{ per qualche componente fortemente connessa
        C}) \}\}
  \end{split}
\end{displaymath}
Pu\`o sembrare criptico ma non cattura un concetto difficile. Il
valore che la funzione $lowlink$ associa ad un vertice $v$ \`e il
minimo valore associato ad un vertice $w$ appartenente alla stessa
componente fortemente connessa di $v$, attraversando un numero
qualsiasi di archi seguito da un arco all'indietro.

Pertanto un vertice $v$ \`e la \emph{testa} di una componente
fortemente connessa solo quando da $v$ non \`e possibile n\'e arrivare
in sotto alberi con numerazioni minori (in quanto i vertici in questi
contenuti sono gi\`a stati assegnati ad alcune componenti fortemente
connesse), n\'e raggiungere un antenato (altrimenti non sarebbe la
\emph{testa} della componente fortemente connessa). Quanto detto \`e
quello che esprime $numero(v) = lowlink(v)$.
\\\\
Questo algoritmo lavora in tempo polinomiale in quanto il tempo per
calcolare la funzione $lowlink$ \`e costante ed ogni vertice viene
inserito nella pila una e una sola volta. Inoltre, per verificare se
un vertice \`e contenuto nella pila, possiamo utilizzare un vettore di
valori booleani, che rende il costo di questa operazione lineare.

\subsection{Algoritmo di Tarjan mediante due pile}
\label{subsection:crescenzi-gambosi-grossi}
Anche questa variante personalizza lo schema classico della visita in
profondit\`a, utilizzando gli stessi punti di estensione della
versione descritta nella Sezione \ref{subsection:tarjan-algorithm}.
\\\\
Il metodo che descriviamo classifica i vertici in due insiemi:
\begin{description}
\item[completi] sono tutti i vertici completamente visitati ed
  assegnati ad una componente fortemente connessa;
\item[parziali] sono tutti i vertici appartenenti ad un cammino
  relativo ad una esecuzione della visita, di cui alcuni possono
  essere gi\`a visitati, ma non ancora associati ad una componente
  fortemente connessa.
\end{description}
In base a questa classificazione, possiamo indurne una sulle
componenti fortemente connesse, avendo rispettivamente delle
componenti \emph{complete}, \emph{parziali} oppure
\emph{ignote}. Questa classificazione viene mantenuta in modo
esplicito usando un vettore che associa ad ogni vertice un valore
booleano.

Lo stesso concetto esiste nella versione di Tarjan, codificato come
segue: se $lowlink(v) < numero(v) \wedge v \in Pila$ allora $v$ \`e
parziale, altrimenti \`e completo.
\\\\
Un altro concetto in comune con la variante di Tarjan \`e quello di
\emph{rappresentante} di una componente fortemente connessa. Un
vertice $v$ si dice \emph{rappresentante} della propria componente
fortemente connessa se \`e il primo vertice della componente
fortemente connessa ad esser stato visitato. Il lettore noter\`a
subito che \`e possibile mappare questo concetto su quello di
\emph{testa} utilizzato nella variante di Tarjan. Un'altra
osservazione \`e necessaria:
\begin{quotation}
  Quando una componente fortemente connessa diviene \emph{completa},
  tutti i vertici in essa contenuti divengono a loro volta
  \emph{completi} e i vertici che sono dei \emph{rappresentanti}
  perdono tale ruolo.
\end{quotation}
Questo implica che se un vertice ha il ruolo di rappresentante allora
appartiene ad una componente parziale.

Inoltre i vertici rappresentanti permettono di distinguere l'inizio di
una componente fortemente connessa dalla successiva e, come vedremo,
vengono numerati in ordine crescente rispetto al momento in cui
vengono visitati (anche questo concetto lo si ritrova nella variante
di Tarjan dove si utilizza la funzione $numero$).
\\\\
Questa variante, a regime, mantiene due pile: una per mantenere
l'insieme dei vertici parziali, una per mantenere l'insieme dei
vertici rappresentanti. Tutti i vertici che appartengo alla stessa
componente fortemente connessa occupano posizioni contigue nella pila
dei parziali, mentre il primo di essi sar\`a inserito anche nella pila
dei rappresentanti e vi rester\`a finch\`e la componente fortemente
connessa non verr\`a creata.

L'algoritmo che implementa questa variante procede seguendo la
seguente idea:
\begin{quotation}
  Ogni volta che un nuovo vertice $v$ viene raggiunto, si inserisce
  $v$ nelle due pile ed invochiamo ricorsivamente la procedura per
  ogni vertice vicino di $v$. Se invece $v$ \`e gi\`a stato visitato,
  si estrae dalla pila dei rappresentati finch\`e in testa non appare
  un vertice $w$ tale che $numero(w) \leq numero(v)$.
\end{quotation}
Inizialmente ogni nuovo vertice raggiunto viene inserito in entrambe
le pile in quanto potrebbe essere il rappresentante di una nuova
componente fortemente connessa.

Commentiamo brevemente quando si debbono estrarre i vertici dalla pila
dei rappresentanti: se, scandendo il vicinato, esiste un vertice $w$
gi\`a visitato ma non completo, significa che l'arco attraversato per
arrivare in $w$ comporta un ciclo e, quindi, si possono rimuovere
dalla pila dei rappresentanti tutti i vertici che sono sopra $w$. Se
invece $w$ fosse completo allora appartiene gi\`a ad una componente
fortemente connessa, e l'arco attraversato \`e un arco trasversale,
come chiamato nella variante di Tarjan.

Infine, come nella variante di Tarjan, si costruisce una componente
fortemente connessa quando un vertice, dopo aver completato la visita
del suo vicinato, si trova in testa nella pila dei rappresentanti. La
nuova componente fortemente connessa sar\`a composta da tutti i
vertici contenuti nella pila dei parziali, contenuti tra la cima della
pila e la posizione del rappresentante compresa. Ognuno di loro viene
marcato come completo e si continua l'eventuale computazione.
\\\\
Anche per questa variante il tempo richiesto \`e lineare: ogni vertice
viene inserito ed estratto al pi\`u una volta in ogni pila (il caso
degenere \`e un grafo i cui vertici sono tutti isolati, per cui ogni
vertice corrisponde ad una componente fortemente connessa), non
aggiungendo asintoticamente niente al tempo richiesto dalla visita in
profondit\`a.




